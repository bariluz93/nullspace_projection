{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26682/3530669359.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'autoreload'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minlp_dataset_handler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0minlp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minlp_linear_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cs/labs/gabis/bareluz/nematus_clean/nullspace_projection/src/inlp-oop/inlp.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minlp_dataset_handler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0minlp_linear_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_rowspace_projection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cs/labs/gabis/bareluz/nematus_clean/nullspace_projection/src/inlp-oop/inlp_linear_model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mSiameseLinearClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLinearModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msiamese_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSiamese\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cs/labs/gabis/bareluz/nematus_clean/nullspace_projection/src/inlp-oop/inlp_linear_model.py\u001b[0m in \u001b[0;36mSiameseLinearClassifier\u001b[0;34m()\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mSiameseLinearClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLinearModel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msiamese_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSiamese\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m         \"\"\"\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'siamese_model' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'siamese_model' is not defined",
     "output_type": "error"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "import inlp_dataset_handler\n",
    "import inlp\n",
    "import inlp_linear_model\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression, Ridge, SGDClassifier\n",
    "from sklearn.svm import LinearSVC, SVR\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn import cluster\n",
    "from sklearn.cluster import KMeans\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def tsne(vecs, labels, title=\"\", ind2label = None, words = None, metric = \"l2\"):\n",
    "\n",
    "  tsne = TSNE(n_components=2)#, angle = 0.5, perplexity = 20)\n",
    "  vecs_2d = tsne.fit_transform(vecs)\n",
    "  label_names = sorted(list(set(labels.tolist())))\n",
    "  num_labels = len(label_names)\n",
    "\n",
    "  names = sorted(set(labels.tolist()))\n",
    "\n",
    "  plt.figure(figsize=(6, 5))\n",
    "  colors = \"red\", \"blue\"\n",
    "  for i, c, label in zip(sorted(set(labels.tolist())), colors, names):\n",
    "     plt.scatter(vecs_2d[labels == i, 0], vecs_2d[labels == i, 1], c=c,\n",
    "                label=label if ind2label is None else ind2label[label], alpha = 0.3, marker = \"s\" if i==0 else \"o\")\n",
    "     plt.legend(loc = \"upper right\")\n",
    "\n",
    "  plt.title(title)\n",
    "  plt.show()\n",
    "  #return vecs_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26682/3150479068.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_dev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_dev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_dev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_dev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0minlp_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minlp_dataset_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClassificationDatasetHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train_main\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_dev_main\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mequal_chance_for_main_task_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# a wrapper over the dataset.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error"
    }
   ],
   "source": [
    "x_train, x_dev = np.random.rand(4000,100) - 0.5, np.random.rand(2000,100) - 0.5\n",
    "y_train, y_dev = np.sum(x_train, axis = 1) > 0, np.sum(x_dev, axis = 1) > 0\n",
    "y_train, y_dev = y_train.astype(float), y_dev.astype(int)\n",
    "\n",
    "inlp_dataset = inlp_dataset_handler.ClassificationDatasetHandler(x_train, y_train, x_dev, y_dev, dropout_rate = 0, Y_train_main = None, Y_dev_main = None, by_class = False, equal_chance_for_main_task_labels = False) # a wrapper over the dataset.\n",
    "# the parameters 'Y_train_main', 'Y_dev_main', 'by_class', 'equal_chance_for_main_task_labels' are only relevant if one wants to perform debiasing per main-task label class (e.g. for each sentiment group). In this case, the user has to provide main task labels (e.g. sentiment) and not only protected attribute labels (e.g. gender).\n",
    "#inlp_model_handler = inlp_linear_model.SKlearnClassifier(LinearSVC, {\"dual\": False}) # a wrapper over a Sklearn classifier. Here we use LinearSVC with the parameter \"dual\"=False\n",
    "inlp_model_handler = inlp_linear_model.TorchLinearModel(100, \"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "P, rowspace_projections, Ws = inlp.run_INLP(num_classifiers = 3, input_dim = 100, is_autoregressive = True, min_accuracy = 0, dataset_handler = inlp_dataset, model = inlp_model_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstrate that the data is separable on the rowspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "P_rowspace = np.eye(100)  - P\n",
    "tsne(x_dev[:1000], y_dev[:1000])\n",
    "x_dev_rowspace = P_rowspace.dot(x_dev.T).T\n",
    "tsne(x_dev_rowspace[:1000], y_dev[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def do_sanity_check(P, Ws, x_train):\n",
    "\n",
    "    assert np.allclose(P.dot(P), P)\n",
    "    assert np.allclose(Ws[0].dot(P.dot(x_train[0])), 0.0)\n",
    "\n",
    "    for w in Ws:\n",
    "        for w2 in Ws:\n",
    "            if w is w2: continue\n",
    "            assert np.allclose(w.dot(w2.T).item(), 0.0)\n",
    "            \n",
    "do_sanity_check(P, Ws, x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Siamese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "x_train1, x_train2 = np.random.rand(1000,100) - 0.5,  np.random.rand(1000,100) - 0.5,\n",
    "x_dev1, x_dev2 =  np.random.rand(1000,100) - 0.5, np.random.rand(1000,100) - 0.5\n",
    "\n",
    "y_train = (np.sign(np.sum(x_train1, axis = 1)) ==  np.sign(np.sum(x_train2, axis = 1))).astype(int)\n",
    "y_dev = (np.sign(np.sum(x_dev1, axis = 1)) ==  np.sign(np.sum(x_dev2, axis = 1))).astype(int)\n",
    "\n",
    "inlp_dataset = inlp_dataset_handler.SiameseDatasetHandler((x_train1, x_train2), y_train, (x_dev1, x_dev2), y_dev, dropout_rate = 0, Y_train_main = None, Y_dev_main = None, by_class = False, equal_chance_for_main_task_labels = False)\n",
    "params = {\"num_iter\": 25, \"input_dim\": 100, \"hidden_dim\": 32, \"batch_size\": 32, \"verbose\": False, \"device\": \"cuda\",\n",
    "         \"compare_by\": \"cosine\", \"same_weights\": True}\n",
    "inlp_model_handler = inlp_linear_model.SiameseLinearClassifier(model_params = params, concat_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#inlp_model_handler.train_model(inlp_dataset)\n",
    "P, rowspace_projections, Ws = inlp.run_INLP(num_classifiers = 3, input_dim = 100, is_autoregressive = True, min_accuracy = 0, dataset_handler = inlp_dataset, model = inlp_model_handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## note that the cosine/l2 distance loss is no longer convex, so w_i.dot(w_j) != 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "Ws[0].dot(Ws[1].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "print(np.linalg.norm(P.dot(P) - P))\n",
    "print( np.linalg.norm( Ws[-1][:32, :].dot(P.dot(x_train1[0]))) ) # note that the norm is not exactly 0 due to pytorch floating point precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric Siamese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.utils import shuffle\n",
    "import random\n",
    "mnist = fetch_openml('mnist_784')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "COLOR_MNIST = True\n",
    "\n",
    "if not COLOR_MNIST:\n",
    "    X,Y = mnist.data, np.array([int(y) for y in mnist.target])\n",
    "    X,Y = shuffle(X,Y)\n",
    "    X_strs = np.array([\"\"]*len(X))\n",
    "else:\n",
    "    \n",
    "    with open(\"mnist.colored.dict.pickle\", \"rb\") as f:    \n",
    "        data = pickle.load(f)\n",
    "    X = np.array([d[\"x\"].reshape(-1) for d in data])\n",
    "    Y = np.array([int(d[\"y\"]) for d in data])\n",
    "    X_strs = np.array([d[\"color\"][0] for d in data])\n",
    "\n",
    "X_mean = np.mean(X, axis = 0, keepdims = True)\n",
    "X -= X_mean\n",
    "\n",
    "data = []\n",
    "label_set = range(10)\n",
    "k = 2000 # num examples per digit\n",
    "\n",
    "for y in label_set:\n",
    "    \n",
    "    idx = Y == y\n",
    "    relevant = X[idx]\n",
    "    \n",
    "    x1_idx, x2_idx = np.random.choice(relevant.shape[0], k, replace=False), np.random.choice(relevant.shape[0], k, replace=False)\n",
    "    x1 = relevant[x1_idx, :]\n",
    "    x2 = relevant[x2_idx, :]\n",
    "    \n",
    "    x1_strs, x2_strs = X_strs[x1_idx], X_strs[x2_idx]\n",
    "    \n",
    "    tuples = list(zip(x1,x2))\n",
    "    ids = [(y,y)]*k\n",
    "    strs = list(zip(x1_strs, x2_strs)) #[(\"\", \"\")]*k\n",
    "    data.extend(list(zip(tuples, strs, ids)))\n",
    "\n",
    "random.shuffle(data)\n",
    "l = int(0.8*len(data))\n",
    "train,dev = data[:l], data[l:]\n",
    "\n",
    "\n",
    "\n",
    "x_train, sents_train, ids_train = map(list, zip(*train))\n",
    "x_train1, x_train2 = map(np.array, zip(*x_train))\n",
    "sents_train1, sents_train2 = map(np.array, zip(*sents_train))\n",
    "ids_train1, ids_train2 = map(np.array, zip(*ids_train))\n",
    "\n",
    "x_dev, sents_dev, ids_dev = map(list, zip(*dev))\n",
    "x_dev1, x_dev2 = map(np.array, zip(*x_dev))\n",
    "sents_dev1, sents_dev2 = map(np.array, zip(*sents_dev))\n",
    "ids_dev1, ids_dev2 = map(np.array, zip(*ids_dev))\n",
    "\n",
    "#x_train1, x_train2, x_dev1, x_dev2 = np.map(np.array, zip(*train, np.array(x_dev1), np.array(x_dev2)\n",
    "#sents_train1, sents_train2, sents_dev1, sents_dev2 = np.array(sents_train1), np.array(sents_train2), np.array(sents_dev1), np.array(sents_dev2)\n",
    "#ids_train1, ids_train2, ids_dev1, ids_dev2 = np.array(ids_train1), np.array(ids_train2), np.array(ids_dev1), np.array(ids_dev2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "x = x_dev1[0]\n",
    "np.mean(X, axis = 0)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "del x_train\n",
    "del x_dev\n",
    "del train\n",
    "del dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def show_some_images(images, n = 3, grayscale = True):\n",
    "  \n",
    "  for index, image in enumerate(images[:n]):\n",
    "    if grayscale:\n",
    "        plt.imshow(image.reshape(28,28),cmap='gray')\n",
    "    else:\n",
    "        plt.imshow(image.reshape(28,28,3))\n",
    "    plt.show()\n",
    "show_some_images(x_dev1 + X_mean, grayscale = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "siamese_dataset_handler = inlp_dataset_handler.MetricSiameseDatasetHandler((x_train1, x_train2), (x_dev1, x_dev2), (sents_train1, sents_train2), (ids_train1, ids_train2),(sents_dev1, sents_dev2), (ids_dev1, ids_dev2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from siamese_model import SiameseMetric\n",
    "params = {\"input_dim\": x_train1.shape[1], \"hidden_dim\": 32, \"batch_size\": 32, \"verbose\": False,\n",
    "         \"k\": 1, \"p\": 2, \"alpha\": 0.5, \"mode\": \"cosine\", \"final\": \"softmax\", \"device\": \"cpu\", \"num_iter\": 5,\n",
    "         \"bias\": False, \"optimizer_type\": \"sgd\", \"l1_coeff\": 0.5*1e-4}\n",
    "inlp_model_handler = inlp_linear_model.SiameseMetricLearning(model_class = SiameseMetric, model_params = params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "P, rowspace_projections, Ws = inlp.run_INLP(num_classifiers = 2, input_dim = x_train1.shape[1], is_autoregressive = True, min_accuracy = 0, dataset_handler = siamese_dataset_handler, model = inlp_model_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "P_rowspace = np.eye(x_dev1.shape[1]) - P\n",
    "w_concat = np.concatenate(Ws[:])\n",
    "P_concat = inlp.get_rowspace_projection(w_concat)\n",
    "assert np.allclose(P_rowspace, P_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def tsne(vecs, labels, title=\"\", words = None, metric = \"l2\", color_gradient = False):\n",
    "\n",
    "  tsne = TSNE(n_components=2, random_state=0, metric = metric)\n",
    "  vecs_2d = tsne.fit_transform(vecs)\n",
    "  num_labels = len(set(labels.tolist()))\n",
    "\n",
    "  #names = [\"digit={}\".format(int(i)) for i in labels.tolist()]\n",
    "  #names = [\"class {}\".format(i) for i in range(num_labels)]\n",
    "  names = sorted(set(labels.tolist()))\n",
    "  \n",
    "\n",
    "  if not color_gradient:\n",
    "      plt.figure(figsize=(6, 5))\n",
    "      colors = \"red\", \"green\", \"blue\", \"cyan\", \"yellow\", \"orange\", \"brown\", \"black\", \"purple\", \"pink\"\n",
    "      #colors = [(255,13,12) for n in names]\n",
    "    \n",
    "      for i, c, label in zip(sorted(set(labels.tolist())), colors, names):\n",
    "        #print(len(vecs_2d[labels == i, 0]))\n",
    "        plt.scatter(vecs_2d[labels == i, 0], vecs_2d[labels == i, 1], c=c,\n",
    "                    label=label, alpha = 0.3)\n",
    "      plt.legend()\n",
    "  \n",
    "  else:\n",
    "        fig, ax = plt.subplots()\n",
    "        N = num_labels\n",
    "        # define the colormap\n",
    "        cmap = plt.cm.jet\n",
    "        # extract all colors from the .jet map\n",
    "        cmaplist = [cmap(i) for i in range(cmap.N)]\n",
    "        # create the new map\n",
    "        cmap = cmap.from_list('Custom cmap', cmaplist, cmap.N)\n",
    "        # define the bins and normalize\n",
    "        bounds = np.linspace(0, N, N + 1)\n",
    "        norm = matplotlib.colors.BoundaryNorm(bounds, cmap.N)\n",
    "\n",
    "        scat = ax.scatter(vecs_2d[:, 0], vecs_2d[:, 1], c = labels, cmap=cmap, norm=norm, alpha=1)\n",
    "        cb = plt.colorbar(scat, spacing='proportional', ticks=bounds)\n",
    "        cb.set_label(\"label\")\n",
    "\n",
    "  plt.title(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tsne by mnist digit indentity, before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "tsne(x_dev1[:1200], ids_dev1[:1200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tsne by mnist digit indentity, rowspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "tsne(P_concat.dot(x_dev1.T).T[:1200], ids_dev1[:1200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tsne by mnist digit identity, concat-rowspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#tsne(P_concat.dot(x_dev1.T).T[:2000], ids_dev1[:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tsne by mnist digit indentity, nullspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "tsne(P.dot(x_dev1.T).T[:1200], ids_dev1[:1200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def compute_v_measure(vecs, labels_true, k=10):\n",
    "        np.random.seed(0)\n",
    "        clustering = sklearn.cluster.KMeans(n_clusters = k, random_state = 0)\n",
    "        clustering.fit(vecs)\n",
    "        labels_pred = clustering.labels_\n",
    "        return sklearn.metrics.v_measure_score(labels_true, labels_pred)\n",
    "\n",
    "k = 10 #len(set(data_for_tsen_deps.tolist()))\n",
    "v_before = compute_v_measure(x_dev1[:5000], ids_dev1[:5000], k = k)\n",
    "v_rowspace = compute_v_measure(P_rowspace.dot(x_dev1.T).T[:5000], ids_dev1[:5000], k = k)\n",
    "v_nullspace = compute_v_measure(P.dot(x_dev1.T).T[:5000], ids_dev1[:5000], k = k)\n",
    "print(\"V measure, original: {}\\n V-measure, INLP-rowspace: {}\\n V-measure, INLP-nullspace: {}\".format(v_before, v_rowspace, v_nullspace))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "show_some_images(P_rowspace.dot(x_dev1.T).T, n = 10, grayscale=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-604e21ab",
   "language": "python",
   "display_name": "PyCharm (nematus_clean)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}