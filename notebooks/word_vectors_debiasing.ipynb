{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "sys.path.append(\"../data/embeddings\")\n",
    "import classifier\n",
    "import debias\n",
    "#import debias_old as debias\n",
    "import gensim\n",
    "import codecs\n",
    "import json\n",
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "import random\n",
    "import sklearn\n",
    "from sklearn import model_selection\n",
    "from sklearn import cluster\n",
    "from sklearn import metrics\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.linear_model import SGDClassifier, Perceptron, LogisticRegression, PassiveAggressiveClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import PCA\n",
    "import scipy\n",
    "from scipy import linalg\n",
    "from scipy.stats.stats import pearsonr\n",
    "import tqdm\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['agg.path.chunksize'] = 10000\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "#import warnings\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def tsne(vecs, labels, title=\"\", ind2label = None, words = None, metric = \"l2\"):\n",
    "\n",
    "  tsne = TSNE(n_components=2)#, angle = 0.5, perplexity = 20)\n",
    "  vecs_2d = tsne.fit_transform(vecs)\n",
    "  label_names = sorted(list(set(labels.tolist())))\n",
    "  num_labels = len(label_names)\n",
    "\n",
    "  names = sorted(set(labels.tolist()))\n",
    "\n",
    "  plt.figure(figsize=(6, 5))\n",
    "  colors = \"red\", \"blue\"\n",
    "  for i, c, label in zip(sorted(set(labels.tolist())), colors, names):\n",
    "     plt.scatter(vecs_2d[labels == i, 0], vecs_2d[labels == i, 1], c=c,\n",
    "                label=label if ind2label is None else ind2label[label], alpha = 0.3, marker = \"s\" if i==0 else \"o\")\n",
    "     plt.legend(loc = \"upper right\")\n",
    "\n",
    "  plt.title(title)\n",
    "  plt.savefig(\"embeddings.{}.png\".format(title), dpi=600)\n",
    "  plt.show()\n",
    "  return vecs_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading & processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def load_word_vectors(fname):\n",
    "    \n",
    "    model = KeyedVectors.load_word2vec_format(fname, binary=False)\n",
    "    vecs = model.vectors\n",
    "    words = list(model.vocab.keys())\n",
    "    return model, vecs, words\n",
    "\n",
    "def project_on_gender_subspaces(gender_vector, model: Word2VecKeyedVectors, n = 2500):\n",
    "    \n",
    "    group1 = model.similar_by_vector(gender_vector, topn = n, restrict_vocab=None)\n",
    "    group2 = model.similar_by_vector(-gender_vector, topn = n, restrict_vocab=None)\n",
    "    \n",
    "    all_sims = model.similar_by_vector(gender_vector, topn = len(model.vectors), restrict_vocab=None)\n",
    "    eps = 0.03\n",
    "    idx = [i for i in range(len(all_sims)) if abs(all_sims[i][1]) < eps]\n",
    "    samp = set(np.random.choice(idx, size = n))\n",
    "    neut = [s for i,s in enumerate(all_sims) if i in samp]\n",
    "    return group1, group2, neut\n",
    "\n",
    "def get_vectors(word_list: list, model: Word2VecKeyedVectors):\n",
    "    \n",
    "    vecs = []\n",
    "    for w in word_list:\n",
    "        \n",
    "        vecs.append(model[w])\n",
    "    \n",
    "    vecs = np.array(vecs)\n",
    "\n",
    "    return vecs\n",
    "    \n",
    "def get_bias_by_neighbors(model, v, gender_direction, topn): \n",
    "    \n",
    "    neighbors = model.similar_by_vector(v, topn = topn) \n",
    "    neighbors_words = [n for n, _ in neighbors]\n",
    "    \n",
    "    #bias = len([n for n in neighbors_words if n in gendered_words])\n",
    "    bias = len([n for n in neighbors_words if model.cosine_similarities(model[n], [gender_direction])[0] > 0])\n",
    "    bias /= (1.*topn)\n",
    "    return bias\n",
    "\n",
    "\n",
    "def save_in_word2vec_format(vecs: np.ndarray, words: np.ndarray, fname: str):\n",
    "\n",
    "\n",
    "    with open(fname, \"w\", encoding = \"utf-8\") as f:\n",
    "\n",
    "        f.write(str(len(vecs)) + \" \" + \"300\" + \"\\n\")\n",
    "        for i, (v,w) in tqdm.tqdm_notebook(enumerate(zip(vecs, words))):\n",
    "\n",
    "            vec_as_str = \" \".join([str(x) for x in v])\n",
    "            f.write(w + \" \" + vec_as_str + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31933/1322974002.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 150k top vectors (with gender-typical words) - used for training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_word_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../data/embeddings/vecs.filtered.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# only gendered vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_31933/2258971508.py\u001b[0m in \u001b[0;36mload_word_vectors\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/gabi_labs/nematus_clean/nullspace_projection/null_space/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mvocab\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    660\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         raise AttributeError(\n\u001b[0;32m--> 662\u001b[0;31m             \u001b[0;34m\"The vocab attribute was removed from KeyedVector in Gensim 4.0.0.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m             \u001b[0;34m\"Use KeyedVector's .key_to_index dict, .index_to_key list, and methods \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m             \u001b[0;34m\".get_vecattr(key, attr) and .set_vecattr(key, attr, new_val) instead.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: The vocab attribute was removed from KeyedVector in Gensim 4.0.0.\nUse KeyedVector's .key_to_index dict, .index_to_key list, and methods .get_vecattr(key, attr) and .set_vecattr(key, attr, new_val) instead.\nSee https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4"
     ],
     "ename": "AttributeError",
     "evalue": "The vocab attribute was removed from KeyedVector in Gensim 4.0.0.\nUse KeyedVector's .key_to_index dict, .index_to_key list, and methods .get_vecattr(key, attr) and .set_vecattr(key, attr, new_val) instead.\nSee https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4",
     "output_type": "error"
    }
   ],
   "source": [
    "# 150k top vectors (with gender-typical words) - used for training\n",
    "\n",
    "model, vecs, words = load_word_vectors(fname = \"../data/embeddings/vecs.filtered.txt\")\n",
    "\n",
    "# only gendered vectors\n",
    "\n",
    "model_gendered, _, _ = load_word_vectors(fname = \"../data/embeddings/vecs.gendered.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect biased words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "num_vectors_per_class = 7500\n",
    "\n",
    "by_pca = False\n",
    "if by_pca:\n",
    "    pairs = [(\"male\", \"female\"), (\"masculine\", \"feminine\"), (\"he\", \"she\"), (\"him\", \"her\")]\n",
    "    gender_vecs = [model[p[0]] - model[p[1]] for p in pairs]\n",
    "    pca = PCA(n_components=1)\n",
    "    pca.fit(gender_vecs)\n",
    "    gender_direction = pca.components_[0]\n",
    "    \n",
    "else:\n",
    "    gender_direction = model[\"he\"]-model[\"she\"] \n",
    "\n",
    "\n",
    "gender_unit_vec = gender_direction/np.linalg.norm(gender_direction)\n",
    "masc_words_and_scores, fem_words_and_scores, neut_words_and_scores = project_on_gender_subspaces(gender_direction, model, n = num_vectors_per_class)\n",
    "\n",
    "masc_words, masc_scores = list(zip(*masc_words_and_scores))\n",
    "neut_words, neut_scores = list(zip(*neut_words_and_scores))\n",
    "fem_words, fem_scores = list(zip(*fem_words_and_scores))\n",
    "masc_vecs, fem_vecs = get_vectors(masc_words, model), get_vectors(fem_words, model)\n",
    "neut_vecs = get_vectors(neut_words, model)\n",
    "\n",
    "n = min(3000, num_vectors_per_class)\n",
    "all_significantly_biased_words = masc_words[:n] + fem_words[:n]\n",
    "all_significantly_biased_vecs =  np.concatenate((masc_vecs[:n], fem_vecs[:n]))\n",
    "all_significantly_biased_labels = np.concatenate((np.ones(n, dtype = int),\n",
    "                                                  np.zeros(n, dtype = int)))\n",
    "\n",
    "all_significantly_biased_words, all_significantly_biased_vecs, all_significantly_biased_labels = sklearn.utils.shuffle(\n",
    "all_significantly_biased_words, all_significantly_biased_vecs, all_significantly_biased_labels)\n",
    "#print(np.random.choice(masc_words, size = 75))\n",
    "print(\"TOP MASC\")\n",
    "print(masc_words[:50])\n",
    "#print(\"LAST MASC\")\n",
    "#print(masc_words[-120:])\n",
    "print(\"-------------------------\")\n",
    "#print(np.random.choice(fem_words, size = 75))\n",
    "print(\"TOP FEM\")\n",
    "print(fem_words[:50])\n",
    "#print(\"LAST FEM\")\n",
    "#print(fem_words[-120:])\n",
    "print(\"-------------------------\")\n",
    "#print(np.random.choice(neut_words, size = 75))\n",
    "print(neut_words[:50])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "print(masc_scores[:10])\n",
    "print(masc_scores[-10:])\n",
    "print(neut_scores[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform train-dev-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "X = np.concatenate((masc_vecs, fem_vecs, neut_vecs), axis = 0)\n",
    "#X = (X - np.mean(X, axis = 0, keepdims = True)) / np.std(X, axis = 0)\n",
    "y_masc = np.ones(masc_vecs.shape[0], dtype = int)\n",
    "y_fem = np.zeros(fem_vecs.shape[0], dtype = int)\n",
    "y_neut = -np.ones(neut_vecs.shape[0], dtype = int)\n",
    "#y = np.concatenate((masc_scores, fem_scores, neut_scores))#np.concatenate((y_masc, y_fem))\n",
    "y = np.concatenate((y_masc, y_fem, y_neut))\n",
    "X_train_dev, X_test, y_train_dev, Y_test = sklearn.model_selection.train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
    "X_train, X_dev, Y_train, Y_dev = sklearn.model_selection.train_test_split(X_train_dev, y_train_dev, test_size = 0.3, random_state = 0)\n",
    "print(\"Train size: {}; Dev size: {}; Test size: {}\".format(X_train.shape[0], X_dev.shape[0], X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "gender_clf = LinearSVC\n",
    "#gender_clf = SGDClassifier\n",
    "#gender_clf = LogisticRegression\n",
    "#gender_clf = LinearDiscriminantAnalysis\n",
    "#gender_clf = Perceptron\n",
    "\n",
    "params_svc = {'fit_intercept': False, 'class_weight': None, \"dual\": False, 'random_state': 0}\n",
    "params_sgd = {'fit_intercept': False, 'class_weight': None, 'max_iter': 1000, 'random_state': 0}\n",
    "params = params_svc\n",
    "#params = {'loss': 'hinge', 'n_jobs': 16, 'penalty': 'l2', 'max_iter': 2500, 'random_state': 0}\n",
    "#params = {}\n",
    "n = 35\n",
    "min_acc = 0\n",
    "is_autoregressive = True\n",
    "dropout_rate = 0\n",
    "\n",
    "P, rowspace_projs, Ws = debias.get_debiasing_projection(gender_clf, params, n, 300, is_autoregressive, min_acc,\n",
    "                                    X_train, Y_train, X_dev, Y_dev,\n",
    "                                       Y_train_main=None, Y_dev_main=None, \n",
    "                                        by_class = False, dropout_rate = dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "np.save(\"P.glove.dim=300.iters=35.npy\", P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the quality of the debiasing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform t-sne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def perform_purity_test(vecs, k, labels_true):\n",
    "        np.random.seed(0)\n",
    "        clustering = sklearn.cluster.KMeans(n_clusters = k)\n",
    "        clustering.fit(vecs)\n",
    "        labels_pred = clustering.labels_\n",
    "        score = sklearn.metrics.homogeneity_score(labels_true, labels_pred)\n",
    "        return score\n",
    "\n",
    "def compute_v_measure(vecs, labels_true, k=2):\n",
    "    \n",
    "        np.random.seed(0)\n",
    "        clustering = sklearn.cluster.KMeans(n_clusters = k)\n",
    "        clustering.fit(vecs)\n",
    "        labels_pred = clustering.labels_\n",
    "        return sklearn.metrics.v_measure_score(labels_true, labels_pred)\n",
    "    \n",
    "\n",
    "# remove neutral class, keep only male and female biased\n",
    "\n",
    "X_dev = X_dev[Y_dev != -1]\n",
    "X_train = X_train[Y_train != -1]\n",
    "X_test = X_test[Y_test != -1]\n",
    "\n",
    "\n",
    "Y_dev = Y_dev[Y_dev != -1]\n",
    "Y_train = Y_train[Y_train != -1]\n",
    "Y_test = Y_test[Y_test != -1]\n",
    "\n",
    "\n",
    "M =  2000\n",
    "ind2label =  {1: \"Male-biased\", 0: \"Female-biased\"}\n",
    "#tsne_before = tsne(all_significantly_biased_vecs[:M], all_significantly_biased_labels[:M], title = \"Original (t=0)\", ind2label =ind2label )\n",
    "tsne_before = tsne(all_significantly_biased_vecs[:M], all_significantly_biased_labels[:M], title = \"Original (t=0)\", ind2label =ind2label )\n",
    "\n",
    "\n",
    "X_dev_cleaned = (P.dot(X_dev.T)).T \n",
    "X_test_cleaned = (P.dot(X_test.T)).T \n",
    "X_trained_cleaned = (P.dot(X_train.T)).T \n",
    "all_significantly_biased_cleaned = P.dot(all_significantly_biased_vecs.T).T\n",
    "\n",
    "#tsne_after = tsne_by_gender(all_significantly_biased_cleaned[:M], all_significantly_biased_labels[:M], title = \"Projected (t = {})\".format(n))\n",
    "tsne_after = tsne(all_significantly_biased_cleaned[:M], all_significantly_biased_labels[:M], title = \"Projected (t={})\".format(n), ind2label =ind2label )\n",
    "\n",
    "#tsne_projection = tsne_by_gender(all_biased_cleaned, all_significantly_biased_labels,title = \"after (all)\", words = all_significantly_biased_words)\n",
    "\n",
    "print(\"V-measure-before (TSNE space): {}\".format(compute_v_measure(tsne_before, all_significantly_biased_labels[:M])))\n",
    "print(\"V-measure-after (TSNE space): {}\".format(compute_v_measure(tsne_after, all_significantly_biased_labels[:M])))\n",
    "\n",
    "#print(\"V-measure-before (original space): {}\".format(compute_v_measure(all_significantly_biased_vecs[:M], all_significantly_biased_labels[:M]), k = 2))\n",
    "#print(\"V-measure-after (original space): {}\".format(compute_v_measure(all_significantly_biased_cleaned[:M], all_significantly_biased_labels[:M]), k = 2))\n",
    "print(\"V-measure-before (original space): {}\".format(compute_v_measure(all_significantly_biased_vecs[:M], all_significantly_biased_labels[:M]), k = 2))\n",
    "print(\"V-measure-after (original space): {}\".format(compute_v_measure(X_test_cleaned[:M], Y_test[:M]), k = 2))\n",
    "\n",
    "rank_before = np.linalg.matrix_rank(X_train)\n",
    "rank_after = np.linalg.matrix_rank(X_trained_cleaned)\n",
    "print(\"Rank before: {}; Rank after: {}\".format(rank_before, rank_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "for t in [1,3,12,18,25,35]:\n",
    "    p = debias.get_projection_to_intersection_of_nullspaces(rowspace_projs[:t], 300)\n",
    "    tsne_after = tsne(p.dot(all_significantly_biased_vecs[:M].T).T, all_significantly_biased_labels[:M], title = \"Projected (t={})\".format(t), ind2label =ind2label )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## increase the gender component (not in the paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31933/4154527693.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m for word in [\"quality\", \"mathematics\", \"red\", \"bag\", \"draft\", \"fashion\", \"nurse\", \"teacher\",\n\u001b[1;32m      2\u001b[0m             \"talk\", \"book\"]:\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mv_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mP_rowspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdebias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_rowspace_projection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#np.eye(P.shape[0]) - P\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mP_rowspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error"
    }
   ],
   "source": [
    "\n",
    "for word in [\"quality\", \"mathematics\", \"red\", \"bag\", \"draft\", \"fashion\", \"nurse\", \"teacher\",\n",
    "            \"talk\", \"book\"]:\n",
    "    v_word = model[word]\n",
    "    P_rowspace = debias.get_rowspace_projection(Ws[1]) #np.eye(P.shape[0]) - P\n",
    "    P_rowspace = np.eye(P.shape[0]) - P\n",
    "\n",
    "\n",
    "    v_null, v_row = P.dot(v_word), P_rowspace.dot(v_word)\n",
    "    #v_row = np.where(v_row < 0, v_row, 0.0)\n",
    "    for alpha in [-1,3]: #np.linspace(-1, 3, 100):\n",
    "    \n",
    "        v = v_row * (1 + alpha) + v_null * 1.0\n",
    "        u, _ =  list(zip(*model.similar_by_vector((v/np.linalg.norm(v))*np.linalg.norm(v_word), topn = 100, restrict_vocab=None)))\n",
    "        print(\"word={}; alpha= {}; neighbors: {}\".format(word, alpha, u[:8]))\n",
    "        print(\"------------------\")\n",
    "    print(\"========================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train linear & nonlinear classifiers for gender prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "nonlinear_clf = SVC(kernel = \"rbf\")\n",
    "print(\"Before, rbf-svm:\")\n",
    "nonlinear_clf.fit(X_train, Y_train)\n",
    "print(nonlinear_clf.score(X_dev, Y_dev))\n",
    "\n",
    "\"\"\" \n",
    "print(\"Before, linear:\")\n",
    "linear_clf = LinearSVC(dual=False, max_iter = 1500)\n",
    "linear_clf.fit(X_train, Y_train)\n",
    "print(linear_clf.score(X_test, Y_test))\n",
    "\n",
    "print(\"After, linear:\")\n",
    "linear_clf = LinearSVC(dual=False, max_iter = 1500)\n",
    "linear_clf.fit(X_trained_cleaned, Y_train)\n",
    "print(linear_clf.score(X_test_cleaned, Y_test))\n",
    "\n",
    "print(\"After, rbf-svm:\")\n",
    "nonlinear_clf = SVC(kernel = \"rbf\")\n",
    "nonlinear_clf.fit(X_trained_cleaned, Y_train)\n",
    "print(nonlinear_clf.score(X_dev_cleaned, Y_dev))\n",
    "\n",
    "print(\"After, mlp:\")\n",
    "nonlinear_clf = MLPClassifier(hidden_layer_sizes = 256, activation = \"relu\")\n",
    "\n",
    "nonlinear_clf.fit(X_trained_cleaned, Y_train)\n",
    "print(nonlinear_clf.score(X_dev_cleaned, Y_dev))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The information is still recoverable by nonlinear model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### project on the gender direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "masc_vecs_cleaned = P.dot(masc_vecs.T).T\n",
    "fem_vecs_cleaned = P.dot(fem_vecs.T).T\n",
    "\n",
    "print(\"masc-bias-before: {}\".format(masc_vecs.dot(gender_unit_vec).mean()))\n",
    "print(\"masc-bias-after: {}\".format(masc_vecs_cleaned.dot(gender_unit_vec.dot(P)).mean()))\n",
    "print(\"fem-bias-before: {}\".format(fem_vecs.dot(gender_unit_vec).mean()))\n",
    "print(\"fem-bias-after: {}\".format(fem_vecs_cleaned.dot(gender_unit_vec.dot(P)).mean()))      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculate the similarity matrix before and after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_distance_matrix(vecs: np.ndarray):\n",
    "\n",
    "  distances = sklearn.metrics.pairwise_distances(vecs, vecs, metric=\"cosine\")\n",
    "  return distances\n",
    "\n",
    "def plot_distance(distance_before, distance_after):\n",
    "\n",
    "    idx = distance_before < 0.75 # we are only interested in the relatively close words\n",
    "\n",
    "    distance_before = distance_before.copy()[idx]\n",
    "    distance_after = distance_after.copy()[idx]\n",
    "    \n",
    "    chosen = np.random.rand(len(distance_before)) < 0.01\n",
    "    before = distance_before[chosen]\n",
    "    after = distance_after[chosen]\n",
    "    plt.plot(before, after, linestyle=\"None\", marker = \"*\", alpha = 0.1)\n",
    "    plt.xlabel(\"distnace before\")\n",
    "    plt.ylabel(\"distance after\")\n",
    "\n",
    "    plt.show()\n",
    "    print(\"Correlation: {}\".format(pearsonr(before, after)[0]))\n",
    "    \n",
    "def plot_similarity_change_vs_original_bias(bias_before, distance_before, distance_after):\n",
    "\n",
    "    K = 50\n",
    "    most_similar_idx_before = distance_before.argsort(axis = 0)[:K].T\n",
    "    most_similar_idx_after = distance_after.argsort(axis = 0)[:K].T\n",
    "    data = []\n",
    "    \n",
    "    for i, (bias, dis_before, dis_after) in enumerate(tqdm.tqdm_notebook(zip(bias_before, distance_before, distance_after), ascii = True, total = len(bias_before))):\n",
    "        \n",
    "        idx_before = set(most_similar_idx_before[i].tolist())\n",
    "        idx_after = set(most_similar_idx_after[i].tolist())\n",
    "        intersection = (most_similar_idx_before[i] == most_similar_idx_after[i]).sum() \n",
    "        intersection = idx_before.intersection(idx_after)\n",
    "        data.append((abs(bias), 1 - len(intersection)/K))\n",
    "        #data.append((abs(bias), 1 - intersection/K))\n",
    "        \n",
    "    plt.xlabel(\"change in similarity (% of of top-{}-similar that changed)\".format(K))\n",
    "    plt.ylabel(\"bias before\")\n",
    "    biases, sims = zip(*data)    \n",
    "    plt.plot(sims, biases, linestyle=\"None\", marker = \"*\", alpha = 0.1)\n",
    "\n",
    "    plt.show()\n",
    "    print(\"Correlation: {}\".format(pearsonr(biases, sims)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "vecs_cleaned = (P.dot(vecs.T)).T\n",
    "save_in_word2vec_format(vecs_cleaned, words, \"../data/embeddings/vecs.150k.cleaned.txt\")\n",
    "model_cleaned, _, _ = load_word_vectors(fname = \"../data/embeddings/vecs.150k.cleaned.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calcualte the similarity of female-stereotyped words to 'girlish', before and after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "w = \"girlish\"\n",
    "k = 5000\n",
    "\n",
    "random_fem_words = np.random.choice(fem_words, size = k)\n",
    "sim_to_girlish_before = [model.similarity(w,w2) for w2 in random_fem_words]\n",
    "sim_to_girlish_after = [model_cleaned.similarity(w,w2) for w2 in random_fem_words]\n",
    "\n",
    "print(\"Similarity of female-stereotyped words to 'girlish' before: {}; similarity after: {}\".format(np.mean(sim_to_girlish_before), np.mean(sim_to_girlish_after)))\n",
    "\n",
    "\n",
    "w = \"girlish\"\n",
    "random_masc_words = np.random.choice(masc_words, size = k)\n",
    "sim_to_girlish_before = [model.similarity(w,w2) for w2 in random_masc_words]\n",
    "sim_to_girlish_after = [model_cleaned.similarity(w,w2) for w2 in random_masc_words]\n",
    "\n",
    "print(\"Similarity of male-stereotyped words to 'girlish' before: {}; similarity after: {}\".format(np.mean(sim_to_girlish_before), np.mean(sim_to_girlish_after)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcualte bias-by-clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def numerical_bias_by_clustering(model_before, model_after, masc_words, fem_words, k):\n",
    "    \n",
    "    scores_before, scores_after = [], []\n",
    "    all_biased = masc_words.union(fem_words)\n",
    "    \n",
    "    for w in all_biased:\n",
    "        \n",
    "        most_similar_before = model_before.most_similar(w, topn = k)\n",
    "        most_similar_before, _ = zip(*most_similar_before)\n",
    "\n",
    "        most_similar_after = model_after.most_similar(w, topn = k)\n",
    "        most_similar_after, _ = zip(*most_similar_after)\n",
    "        \n",
    "        neighbors_biased_before = len([w for w in most_similar_before if w in all_biased])\n",
    "        neighbors_biased_after = len([w for w in most_similar_after if w in all_biased])\n",
    "        scores_before.append(neighbors_biased_before)\n",
    "        scores_after.append(neighbors_biased_after)\n",
    "    print(\"avg. number of biased neighbors before: {}; after: {}\".format(np.mean(scores_before), np.mean(scores_after)))\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#numerical_bias_by_clustering(model, model_cleaned, set(masc_words), set(fem_words), k = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### print the most similar words to random words before and after (to make sure we didn't damage the space too much)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pickle\n",
    "\n",
    "words_chosen = np.random.choice(words[:15000] , size = 40)\n",
    "topn = 3\n",
    "words_before_and_after = defaultdict(dict)\n",
    "gendered_words_before_and_after = defaultdict(dict)\n",
    "\n",
    "for w in words_chosen:\n",
    "    words_and_sims_before = model.most_similar(w, topn = topn)\n",
    "    words__and_sims_after = model_cleaned.most_similar(w, topn = topn)\n",
    "    words_before, sims_before = zip(*words_and_sims_before)\n",
    "    words_after, sims_after = zip(*words__and_sims_after)\n",
    "    words_before_and_after[w][\"before\"] = words_before\n",
    "    words_before_and_after[w][\"after\"] = words_after\n",
    "    print(\"w: {}\\n most-similar-before: {}\\n most-similar-after: {}\".format(w,words_before, words_after))\n",
    "    print(\"----------------------------------\")\n",
    "\n",
    "print(\"====================================================================\\n\\n\")\n",
    "print(\"gendered words:\")\n",
    "words_chosen = [\"miss\", \"mrs\", \"mr\", \"john\", \"rachel\", \"wife\", \"mom\", \"family\", \"father\", \"lady\", \"he\", \"she\"]\n",
    "words_chosen = [\"ruth\", \"charlotte\", \"abigail\", \"sophie\", \"nichole\", \"emma\", \"olivia\", \"ava\", \"isabella\", \"sophia\", \"charlotte\", \"mia\", \"amelia\",\n",
    "                \"james\", \"john\", \"robert\", \"michael\", \"william\", \"david\", \"richard\", \"joseph\", \"thomas\", \"ariel\", \"mike\", \"nurse\", \"mom\", \"secretary\", \"nursery\"]\n",
    "for w in words_chosen:\n",
    "    \n",
    "    words_and_sims_before = model.most_similar(w, topn = topn)\n",
    "    words__and_sims_after = model_cleaned.most_similar(w, topn = topn)\n",
    "    words_before, _ = zip(*words_and_sims_before)\n",
    "    words_after, _ = zip(*words__and_sims_after)\n",
    "    gendered_words_before_and_after[w][\"before\"] = words_before\n",
    "    gendered_words_before_and_after[w][\"after\"] = words_after\n",
    "    print(\"w: {}\\n most-similar-before: {}\\n most-similar-after: {}\".format(w,words_before, words_after))\n",
    "    print(\"----------------------------------\")    \n",
    "    \n",
    "with open(\"words_before_and_after.pickle\", \"wb\") as f:\n",
    "    pickle.dump(words_before_and_after, f)\n",
    "    \n",
    "with open(\"words_before_and_after_gendered.pickle\", \"wb\") as f:\n",
    "    pickle.dump(gendered_words_before_and_after, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "sims_before, sims_after"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bias by profession experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def get_bias_by_neighbors(model, model_cleaned, gendered_words, v, gender_direction): \n",
    "    \n",
    "    neighbors = model_cleaned.similar_by_vector(v, topn=100) \n",
    "    neighbors_words = [n for n, _ in neighbors]\n",
    "    \n",
    "    #bias = len([n for n in neighbors_words if n in gendered_words])\n",
    "    bias = len([n for n in neighbors_words if model.cosine_similarities(model[n], [gender_direction])[0] > 0])\n",
    "    return bias\n",
    "\n",
    "def bias_by_profession(model, model_cleaned, gender_direction, P, masc_words):\n",
    "    \n",
    "    with codecs.open(\"../data/lists/professions.json\") as f:\n",
    "        professions_and_scores = json.load(f)\n",
    "\n",
    "    professions = [p[0] for p in professions_and_scores]\n",
    "    #print(professions)\n",
    "    professions = list(filter(lambda p: p in model, professions))\n",
    "    vecs = np.array([model[p] for p in professions])\n",
    "    vecs_cleaned = vecs.dot(P)\n",
    "    bias_vals = np.array([model.cosine_similarities(gender_direction,vecs)])[0]\n",
    "    #bias_vals_after = np.array([model.cosine_similarities(gender_direction,vecs_cleaned)])[0]\n",
    "    bias_by_neighbors_after = np.array([get_bias_by_neighbors(model, model_cleaned, masc_words, v, gender_direction) for v in vecs_cleaned])\n",
    "    bias_by_neighbors_before = np.array([get_bias_by_neighbors(model, model, masc_words, v, gender_direction) for v in vecs])\n",
    "\n",
    "    #plt.ylim([np.min(bias_vals), np.max(bias_vals)])\n",
    "    plt.plot(bias_vals, bias_by_neighbors_after, marker = \"o\", linestyle = \"none\", color = \"red\", label = \"after\", alpha = 0.25)\n",
    "    plt.plot(bias_vals, bias_by_neighbors_before, marker = \"o\", linestyle = \"none\", color = \"blue\", label = \"before\", alpha = 0.25)\n",
    "    \n",
    "    word_idx_high = np.argsort(bias_vals)[:4] \n",
    "    word_idx_low = np.argsort(bias_vals)[-4:]\n",
    "    word_idx_middle_low = np.argsort(bias_vals)[-55:-51]\n",
    "    word_idx_middle_high = np.argsort(bias_vals)[51:55]\n",
    "    words_biased_fem = [professions[i] for i in word_idx_high]\n",
    "    words_biased_masc = [professions[i] for i in word_idx_low]\n",
    "    mid_low = [professions[i] for i in word_idx_middle_low]\n",
    "    mid_high = [professions[i] for i in word_idx_middle_high]\n",
    "    words = words_biased_masc + words_biased_fem + mid_low + mid_high\n",
    "    \n",
    "    for w in words:\n",
    "        i = professions.index(w)\n",
    "        x1,y1 = bias_vals[i],bias_by_neighbors_after[i]\n",
    "        plt.annotate(w , (x1,y1), size = 8, color = \"red\")\n",
    "        x2,y2 = bias_vals[i],bias_by_neighbors_before[i]\n",
    "        plt.annotate(w, (x2,y2), size = 8, color = \"blue\")\n",
    "        #plt.arrow(x2,y2,x1-x2,y1-y2, width = 0.0005)\n",
    "        \n",
    "    plt.legend()\n",
    "    plt.xlabel(\"bias-by-PROJECTION of the professions before\")\n",
    "    plt.ylabel(\"bias-by-NEIGHBORS\")\n",
    "    plt.title(\"projection bias before vs. neighbors bias before/after \\n(# neighbors closer to 'she' then 'he')\")\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Correlation before: {}, p-value: {}\".format(*pearsonr(bias_vals, bias_by_neighbors_before)))\n",
    "    print(\"Correlation after: {}, p-value: {}\".format(*pearsonr(bias_vals, bias_by_neighbors_after)))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "bias_by_profession(model, model_cleaned, gender_direction, P, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "vecs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word association tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Auxiliary functions for experiments by Caliskan et al.\n",
    "\n",
    "import scipy\n",
    "import scipy.misc as misc\n",
    "import itertools\n",
    "\n",
    "\n",
    "def s_word(w, A, B, model, all_s_words):\n",
    "    \n",
    "    if w in all_s_words:\n",
    "        return all_s_words[w]\n",
    "    \n",
    "    mean_a = []\n",
    "    mean_b = []\n",
    "    \n",
    "    for a in A:\n",
    "        mean_a.append(model.similarity(w,a))\n",
    "    for b in B:\n",
    "        mean_b.append(model.similarity(w,b))\n",
    "        \n",
    "    mean_a = sum(mean_a)/float(len(mean_a))\n",
    "    mean_b = sum(mean_b)/float(len(mean_b))\n",
    "    \n",
    "    all_s_words[w] = mean_a - mean_b\n",
    "\n",
    "    return all_s_words[w]\n",
    "\n",
    "\n",
    "def s_group(X, Y, A, B, model, all_s_words):\n",
    "    \n",
    "    total = 0\n",
    "    for x in X:\n",
    "        x_sim = s_word(x, A, B, model, all_s_words)\n",
    "        total += x_sim\n",
    "    for y in Y:\n",
    "        y_sim =  s_word(y, A, B, model, all_s_words)\n",
    "        total -= y_sim\n",
    "    \n",
    "    #print(x_sim, y_sim)\n",
    "        \n",
    "    return total\n",
    "\n",
    "\n",
    "def p_value_exhust(X, Y, A, B, model):\n",
    "    \n",
    "    if len(X) > 10:\n",
    "        print ('might take too long, use sampled version: p_value')\n",
    "        return\n",
    "    \n",
    "    assert(len(X) == len(Y))\n",
    "    \n",
    "    all_s_words = {}\n",
    "    s_orig = s_group(X, Y, A, B, model, all_s_words)\n",
    "    #print(\"s-orig: {}\".format(s_orig))\n",
    "    \n",
    "    union = set(X+Y)\n",
    "    subset_size = int(len(union)/2)\n",
    "    \n",
    "    larger = 0\n",
    "    total = 0\n",
    "    #all_subs = set(itertools.combinations(union, subset_size))\n",
    "    #print(all_subs)\n",
    "    for subset in tqdm.tqdm_notebook(set(itertools.combinations(union, subset_size))):\n",
    "        total += 1\n",
    "        Xi = list(set(subset))\n",
    "        Yi = list(union - set(subset))\n",
    "        if s_group(Xi, Yi, A, B, model, all_s_words) > s_orig:\n",
    "            larger += 1\n",
    "    #print ('num of samples', total)\n",
    "    return larger/float(total)\n",
    "\n",
    "\n",
    "def p_value_sample(X, Y, A, B, model):\n",
    "    \n",
    "    random.seed(10)\n",
    "    np.random.seed(10)\n",
    "    all_s_words = {}\n",
    "    \n",
    "    assert(len(X) == len(Y))\n",
    "    length = len(X)\n",
    "    \n",
    "    s_orig = s_group(X, Y, A, B, model, all_s_words) \n",
    "    \n",
    "    num_of_samples = min(10000, int(scipy.special.comb(length*2,length)*100))\n",
    "    print ('num of samples', num_of_samples)\n",
    "    larger = 0\n",
    "    for i in range(num_of_samples):\n",
    "        permute = np.random.permutation(X+Y)\n",
    "        Xi = permute[:length]\n",
    "        Yi = permute[length:]\n",
    "        if s_group(Xi, Yi, A, B, model, all_s_words) > s_orig:\n",
    "            larger += 1\n",
    "    \n",
    "    return larger/float(num_of_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Experiment 1\n",
    "\n",
    "A = ['john', 'paul', 'mike', 'kevin', 'steve', 'greg', 'jeff', 'bill']\n",
    "B = ['amy', 'joan', 'lisa', 'sarah', 'diana', 'kate', 'ann', 'donna']\n",
    "\n",
    "C = ['executive', 'management', 'professional', 'corporation', 'salary', 'office', 'business', 'career']\n",
    "D = ['home', 'parents', 'children', 'family', 'cousins', 'marriage', 'wedding', 'relatives']\n",
    "\n",
    "print (p_value_exhust(A, B, C, D, model_cleaned))\n",
    "\n",
    "# Experiment 2\n",
    "\n",
    "E = ['math', 'algebra', 'geometry', 'calculus', 'equations', 'computation', 'numbers', 'addition']\n",
    "F = ['poetry', 'art', 'dance', 'literature', 'novel', 'symphony', 'drama', 'sculpture']\n",
    "\n",
    "print (p_value_exhust(A, B, E, F, model_cleaned))\n",
    "\n",
    "\n",
    "# Experiment 3\n",
    "\n",
    "G = ['science', 'technology', 'physics', 'chemistry', 'einstein', 'nasa', 'experiment', 'astronomy']\n",
    "H = ['poetry', 'art', 'shakespeare', 'dance', 'literature', 'novel', 'symphony', 'drama']\n",
    "\n",
    "print (p_value_exhust(A, B, G, H, model_cleaned))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with debiasing on specific directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#specific_words = [(\"he\", \"she\"), (\"man\", \"woman\"), (\"boy\", \"girl\"), (\"him\", \"her\"), (\"father\", \"mother\"), (\"king\", \"queen\")]\n",
    "specific_words = [\"woman\", \"man\"], [\"girl\", \"boy\"], [\"she\", \"he\"], [\"mother\", \"father\"], [\"daughter\", \"son\"], [\"gal\", \"guy\"], [\"female\", \"male\"], [\"her\", \"his\"], [\"herself\", \"himself\"], [\"mary\", \"john\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "vecs_specific_words = np.array([ [model[p[1]] - model[p[0]]] for p in specific_words])\n",
    "P_by_words = debias.debias_by_specific_directions(vecs_specific_words, 300) # projection matrix generated by zeroing the above directions\n",
    "X_dev_cleaned = (P_by_words.dot(X_dev.T)).T\n",
    "X_train_cleaned = (P_by_words.dot(X_train.T)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "clf = LinearSVC(dual = False)\n",
    "clf.fit(X_train_cleaned, Y_train)\n",
    "print(clf.score(X_dev_cleaned, Y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "P, rowspace_projs, Ws = debias.get_debiasing_projection(gender_clf, params, len(specific_words), 300, is_autoregressive, min_acc,\n",
    "                                    X_train, Y_train, X_dev, Y_dev,\n",
    "                                       Y_train_main=None, Y_dev_main=None, \n",
    "                                        by_class = False, dropout_rate = dropout_rate)\n",
    "\n",
    "clf = LinearSVC(dual = False)\n",
    "clf.fit(P.dot(X_train.T).T, Y_train)\n",
    "print(clf.score(P.dot(X_test.T).T, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA (not in the paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "gender_vecs = [model[p[0]] - model[p[1]] for p in specific_words]\n",
    "pca = PCA(n_components=1)\n",
    "pca.fit(gender_vecs)\n",
    "gender_direction = pca.components_\n",
    "P_by_words_pca = debias.debias_by_specific_directions(np.array([gender_direction]), 300) # projection matrix generated by zeroing the above directions\n",
    "X_dev_cleaned_pca = (P_by_words_pca.dot(X_dev.T)).T\n",
    "X_train_cleaned_pca = (P_by_words_pca.dot(X_train.T)).T\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "clf = LinearSVC(dual = False)\n",
    "clf.fit(X_train_cleaned_pca, Y_train)\n",
    "print(clf.score(X_dev_cleaned_pca, Y_dev))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A linear classifier is still able to recover the gender with non-random accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "M =  2000\n",
    "\n",
    "#tsne_before = tsne_by_gender(all_significantly_biased_vecs[:M], all_significantly_biased_labels[:M], title = \"Original\")\n",
    "X_dev_cleaned = (P_by_words.dot(X_dev.T)).T #X_dev.dot(P)\n",
    "X_test_cleaned = (P_by_words.dot(X_test.T)).T #X_test.dot(P)\n",
    "X_trained_cleaned = (P_by_words.dot(X_train.T)).T #X_train.dot(P)\n",
    "all_significantly_biased_cleaned = P_by_words.dot(all_significantly_biased_vecs.T).T\n",
    "\n",
    "tsne_after = tsne_by_gender(all_significantly_biased_cleaned[:M], all_significantly_biased_labels[:M], title = \"Projected (t = {})\".format(n))\n",
    "print(\"V-measure-before (original space): {}\".format(compute_v_measure(all_significantly_biased_vecs[:M], all_significantly_biased_labels[:M])))\n",
    "print(\"V-measure-after (original space): {}\".format(compute_v_measure(all_significantly_biased_cleaned[:M], all_significantly_biased_labels[:M])))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "model, model_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "w = \"nurse\"\n",
    "w2 = \"doctor\"\n",
    "v_w_before, v_w_after = model[w], model_cleaned[w]\n",
    "v_w2_before, v_w2_after = model[w2], model_cleaned[w2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "np.linalg.norm(v_w_before-v_w2_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "np.linalg.norm(v_w_after-v_w2_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-604e21ab",
   "language": "python",
   "display_name": "PyCharm (nematus_clean)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}